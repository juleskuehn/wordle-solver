{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wordle solver\n",
    "We need to make some assumptions to write an explicit solution, such as:\n",
    "\n",
    "* Words are likely to be the solution proportional to their use in the corpus\n",
    "  * In reality, there may be a non-linear relationship, e.g. square root\n",
    "  * **My intuition is to use metric `letter_freq += 1 + math.sqrt(word_frequency)`** for each occurence of letter\n",
    "* Based on the above, letters are likely to be in the solution proportional to their (weighted) use in the corpus\n",
    "* Getting a \"green\" is more valuable than getting a \"yellow\" (take letter frequency at individual positions into account)\n",
    "* etc.\n",
    "\n",
    "A better solution may be to use reinforcement learning, so as to avoid making these assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from collections import defaultdict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing vocabulary...\n"
     ]
    }
   ],
   "source": [
    "print('Preparing vocabulary...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/rtatman/english-word-frequency?resource=download\n",
    "words = pd.read_csv('./data/unigram_freq.csv')\n",
    "az = string.ascii_lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39933\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>about</td>\n",
       "      <td>1226734006</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>other</td>\n",
       "      <td>978481319</td>\n",
       "      <td>0.797631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>which</td>\n",
       "      <td>810514085</td>\n",
       "      <td>0.660709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>their</td>\n",
       "      <td>782849411</td>\n",
       "      <td>0.638157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>there</td>\n",
       "      <td>701170205</td>\n",
       "      <td>0.571575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word       count      freq\n",
       "35  about  1226734006  1.000000\n",
       "45  other   978481319  0.797631\n",
       "56  which   810514085  0.660709\n",
       "57  their   782849411  0.638157\n",
       "62  there   701170205  0.571575"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter to 5 letter words\n",
    "words = words[words['word'].str.len() == 5]\n",
    "words['freq'] = words['count'] / words['count'].max()\n",
    "print(len(words))\n",
    "words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12947\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nikau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>swack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fyles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0  women\n",
       "1  nikau\n",
       "2  swack\n",
       "3  feens\n",
       "4  fyles"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Allowable wordle words\n",
    "# https://github.com/tabatkins/wordle-list\n",
    "allowed_words = pd.read_csv('./data/wordle-allowed-words.txt', header=None)\n",
    "print(len(allowed_words))\n",
    "allowed_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8072"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter word frequency table to include allowed words only\n",
    "words = words[words['word'].isin(set(allowed_words[0]))]\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12947\n"
     ]
    }
   ],
   "source": [
    "# Add the other allowed words but with count and freq 0\n",
    "counted_words = set(words['word'])\n",
    "for w in allowed_words[0]:\n",
    "    if w not in counted_words:\n",
    "        new_row = {'word': w, 'count':0, 'freq':0}\n",
    "        words = words.append(new_row, ignore_index=True)\n",
    "        \n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Find \"best\" words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('e', 6826.373093957733),\n",
       " ('s', 6797.120446066696),\n",
       " ('a', 6115.552312164332),\n",
       " ('o', 4536.092041527143),\n",
       " ('r', 4266.03717813045)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Letter frequency\n",
    "letter_freq = defaultdict(int)\n",
    "for _, w in words.iterrows():\n",
    "    for char in w['word']:\n",
    "#         Many ways to weight this:\n",
    "#         letter_freq[char] += w['freq']\n",
    "#         letter_freq[char] += 1\n",
    "        letter_freq[char] += 1 + math.sqrt(w['freq'])\n",
    "\n",
    "sorted_letters = sorted(letter_freq.items(), key=lambda x: -x[1])\n",
    "sorted_letters[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('arose', 28541.175071846355),\n",
       " ('soare', 28541.17507184635),\n",
       " ('aeros', 28541.17507184635),\n",
       " ('raise', 27847.75322556465),\n",
       " ('serai', 27847.75322556465)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the best \"starting words\"\n",
    "# Best: maximizing total letter_freq (but 0 score for repeated letter)\n",
    "# This doesn't take into account letter position\n",
    "word_goodness = defaultdict(float)\n",
    "for w in allowed_words[0]:\n",
    "    used_chars = set()\n",
    "    for char in w:\n",
    "        if char in used_chars:\n",
    "            continue\n",
    "        word_goodness[w] += letter_freq[char]\n",
    "        used_chars.add(char)\n",
    "        \n",
    "sorted_words = sorted(word_goodness.items(), key=lambda x: -x[1])\n",
    "sorted_words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s', 1599.4231123478824),\n",
       " ('a', 2308.278555858041),\n",
       " ('a', 1272.652282524225),\n",
       " ('e', 2382.654624241403),\n",
       " ('s', 4028.057199519846)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take letter position into account\n",
    "# Letter frequency per position\n",
    "letter_pos_freq = [defaultdict(float) for _ in range(5)]\n",
    "for _, w in words.iterrows():\n",
    "    for i, char in enumerate(w['word']):\n",
    "#         Many ways to weight this:\n",
    "#         letter_freq[char] += w['freq']\n",
    "#         letter_freq[char] += 1\n",
    "        letter_pos_freq[i][char] += 1 + math.sqrt(w['freq'])\n",
    "\n",
    "sorted_pos_letters = [sorted(letter_pos_freq[i].items(), key=lambda x: -x[1]) for i in range(5)]\n",
    "[s[0] for s in sorted_pos_letters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sores', 11378.663564416172),\n",
       " ('sanes', 11302.442739774659),\n",
       " ('sales', 11184.413237562803),\n",
       " ('sones', 11139.699481722342),\n",
       " ('soles', 11021.669979510487)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the best \"starting words\"\n",
    "# Best: maximizing total letter_freq (but 0 score for repeated letter)\n",
    "# This doesn't take into account letter position\n",
    "word_goodness_pos = defaultdict(float)\n",
    "for w in allowed_words[0]:\n",
    "    used_chars = set()\n",
    "    for i, char in enumerate(w):\n",
    "#         if char in used_chars:\n",
    "#             continue\n",
    "        word_goodness_pos[w] += letter_pos_freq[i][char]\n",
    "        used_chars.add(char)\n",
    "        \n",
    "sorted_words_pos = sorted(word_goodness_pos.items(), key=lambda x: -x[1])\n",
    "sorted_words_pos[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_good_df = pd.DataFrame(dict(word_goodness), index=['']).T\n",
    "word_good_df.columns = ['overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_good_df_pos = pd.DataFrame(dict(word_goodness_pos), index=['']).T\n",
    "word_good_df_pos.columns = ['position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>position</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tares</th>\n",
       "      <td>27396.857394</td>\n",
       "      <td>10781.425154</td>\n",
       "      <td>0.953709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lares</th>\n",
       "      <td>27460.499011</td>\n",
       "      <td>10532.511384</td>\n",
       "      <td>0.943887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cares</th>\n",
       "      <td>26082.927054</td>\n",
       "      <td>10887.691356</td>\n",
       "      <td>0.935361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pares</th>\n",
       "      <td>26061.732612</td>\n",
       "      <td>10820.055129</td>\n",
       "      <td>0.932017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dares</th>\n",
       "      <td>26511.353264</td>\n",
       "      <td>10636.135606</td>\n",
       "      <td>0.931812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            overall      position       avg\n",
       "tares  27396.857394  10781.425154  0.953709\n",
       "lares  27460.499011  10532.511384  0.943887\n",
       "cares  26082.927054  10887.691356  0.935361\n",
       "pares  26061.732612  10820.055129  0.932017\n",
       "dares  26511.353264  10636.135606  0.931812"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_good_df_all = word_good_df.join(word_good_df_pos)\n",
    "word_good_df_all['avg'] = (\n",
    "    (word_good_df_all['overall'] / word_good_df_all['overall'].max())\n",
    "    + (word_good_df_all['position'] / word_good_df_all['position'].max())\n",
    ") / 2\n",
    "best_words = word_good_df_all.sort_values(['avg'], ascending=False)\n",
    "best_words.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Solver (hard mode)\n",
    "This will always use existing clues. Note that this is not an optimal strategy for playing not in hard mode - where using a completely different set of letters is preferred for more information gain.\n",
    "\n",
    "We can define a set of allowable letters for each position, which is initially all letters, then narrows.\n",
    "\n",
    "Start by doing an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>position</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tares</th>\n",
       "      <td>27396.857394</td>\n",
       "      <td>10781.425154</td>\n",
       "      <td>0.953709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lares</th>\n",
       "      <td>27460.499011</td>\n",
       "      <td>10532.511384</td>\n",
       "      <td>0.943887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cares</th>\n",
       "      <td>26082.927054</td>\n",
       "      <td>10887.691356</td>\n",
       "      <td>0.935361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pares</th>\n",
       "      <td>26061.732612</td>\n",
       "      <td>10820.055129</td>\n",
       "      <td>0.932017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dares</th>\n",
       "      <td>26511.353264</td>\n",
       "      <td>10636.135606</td>\n",
       "      <td>0.931812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infix</th>\n",
       "      <td>8299.023116</td>\n",
       "      <td>1674.794133</td>\n",
       "      <td>0.218980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kudzu</th>\n",
       "      <td>7023.637653</td>\n",
       "      <td>2179.129019</td>\n",
       "      <td>0.218799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oxbow</th>\n",
       "      <td>7550.825748</td>\n",
       "      <td>1440.363057</td>\n",
       "      <td>0.195572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>immix</th>\n",
       "      <td>6154.652583</td>\n",
       "      <td>1853.214489</td>\n",
       "      <td>0.189254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xylyl</th>\n",
       "      <td>5849.011578</td>\n",
       "      <td>1750.536914</td>\n",
       "      <td>0.179388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12947 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            overall      position       avg\n",
       "tares  27396.857394  10781.425154  0.953709\n",
       "lares  27460.499011  10532.511384  0.943887\n",
       "cares  26082.927054  10887.691356  0.935361\n",
       "pares  26061.732612  10820.055129  0.932017\n",
       "dares  26511.353264  10636.135606  0.931812\n",
       "...             ...           ...       ...\n",
       "infix   8299.023116   1674.794133  0.218980\n",
       "kudzu   7023.637653   2179.129019  0.218799\n",
       "oxbow   7550.825748   1440.363057  0.195572\n",
       "immix   6154.652583   1853.214489  0.189254\n",
       "xylyl   5849.011578   1750.536914  0.179388\n",
       "\n",
       "[12947 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "green = defaultdict(int)\n",
    "set(green.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_word_list = best_words.index\n",
    "best_word_array = np.array([np.array([c for c in w]) for w in best_word_list])\n",
    "\n",
    "def use_clues(word, result):\n",
    "    # Special case: Same letter is green and grey\n",
    "    # Have to keep track of position of green chars\n",
    "    green_idx = defaultdict(list)\n",
    "    grey = set()\n",
    "    for i, r in enumerate(result):\n",
    "        char = word[i]\n",
    "        if r == 'grey':\n",
    "            grey.add(char)\n",
    "        elif r == 'green':\n",
    "            green_idx[char].append(i)\n",
    "    green_and_grey = set(green_idx.keys()).intersection(grey)\n",
    "    for i, r in enumerate(result):\n",
    "        char = word[i]\n",
    "        if r == 'green':\n",
    "            a[i] = set([char])\n",
    "        elif r == 'yellow':\n",
    "            try:\n",
    "                a[i].remove(char)\n",
    "            except:\n",
    "                continue\n",
    "            b.add(char)\n",
    "        elif r == 'grey':\n",
    "            if char in green_and_grey:\n",
    "                # Remove this option from all but the green positions\n",
    "                for i, pos in enumerate(a):\n",
    "                    if i in green_idx[char]:\n",
    "                        continue\n",
    "                    try:\n",
    "                        pos.remove(char)\n",
    "                    except:\n",
    "                        continue\n",
    "            else:\n",
    "                # Remove from all positions\n",
    "                for pos in a:\n",
    "                    try:\n",
    "                        pos.remove(char)\n",
    "                    except:\n",
    "                        continue\n",
    "        \n",
    "\n",
    "# Find all allowable words matching the constraints\n",
    "def find_ok_words(a, b):\n",
    "    a_met = (\n",
    "        np.in1d(best_word_array[:,0], list(a[0]))\n",
    "        & np.in1d(best_word_array[:,1], list(a[1]))\n",
    "        & np.in1d(best_word_array[:,2], list(a[2]))\n",
    "        & np.in1d(best_word_array[:,3], list(a[3]))\n",
    "        & np.in1d(best_word_array[:,4], list(a[4]))\n",
    "    )\n",
    "#     print('meets a:', a_met.sum())\n",
    "    if len(b) > 0:\n",
    "        b_met_each = []\n",
    "        for char in b:\n",
    "            b_met_each.append(np.array([char in word for word in best_word_list]))\n",
    "        b_met_all = np.array([True] * len(best_word_list))\n",
    "        for b_met in b_met_each:\n",
    "            b_met_all = b_met_all & b_met\n",
    "    else:\n",
    "        b_met_all = np.array([True] * len(best_word_list))\n",
    "#     print('meets b:', b_met_all.sum())\n",
    "    ok_words = best_word_array[a_met & b_met_all]\n",
    "    return [''.join(w) for w in ok_words]\n",
    "\n",
    "# Find the best clue word (most information)\n",
    "def find_clue(a, b):\n",
    "    ok_words = find_ok_words(a, b)\n",
    "    # ok_words is already ranked by how useful the letters are\n",
    "    return ok_words[0]\n",
    "\n",
    "# Find the most likely solution word (most common)\n",
    "def find_solution(a, b):\n",
    "    ok_words = find_ok_words(a, b)\n",
    "    print(len(ok_words), 'matching words.')\n",
    "    # Get the most common word in ok_words\n",
    "    ok_words_sorted = words[words['word'].isin(ok_words)]\n",
    "    return ok_words_sorted['word'].values[0]\n",
    "\n",
    "def find_clues_solutions(a, b):\n",
    "    ok_words = find_ok_words(a, b)\n",
    "    print(len(ok_words), 'matching words. Top picks:\\n')\n",
    "    # Get the most common word in ok_words\n",
    "    most_common_words = words[words['word'].isin(ok_words)]\n",
    "    most_common_words.index = most_common_words['word']\n",
    "    most_common_words = most_common_words[['freq']]\n",
    "    most_common_words.columns = ['Word Frequency']\n",
    "    print('WORD FREQUENCY (most common words):')\n",
    "    print(most_common_words.head())\n",
    "    best_info_words = best_words.loc[ok_words][['avg']]\n",
    "    best_info_words.columns = ['Information Gain']\n",
    "    print('\\nINFORMATION GAIN (frequent letters in common positions):')\n",
    "    print(best_info_words.head())\n",
    "    best_of_both = best_info_words.join(most_common_words)\n",
    "    best_of_both['Combined Score'] = np.sqrt(best_of_both['Word Frequency']) * best_of_both['Information Gain']\n",
    "    best_of_both = best_of_both.sort_values(['Combined Score'], ascending=False)\n",
    "    print('\\nCOMBINED SCORE: (sqrt(word_frequency) * info_gain)')\n",
    "    print(best_of_both[['Combined Score', 'Information Gain', 'Word Frequency']].head(5))\n",
    "    print()\n",
    "    \n",
    "# Shorthands to make entering results easier\n",
    "sh = ['grey', 'yellow', 'green']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORDLE SOLVER\n",
      "With no contraints, there are...\n",
      "12947 matching words. Top picks:\n",
      "\n",
      "WORD FREQUENCY (most common words):\n",
      "       Word Frequency\n",
      "word                 \n",
      "about        1.000000\n",
      "other        0.797631\n",
      "which        0.660709\n",
      "their        0.638157\n",
      "there        0.571575\n",
      "INFORMATION GAIN (frequent letters in common positions):\n",
      "       Information Gain\n",
      "tares          0.953709\n",
      "lares          0.943887\n",
      "cares          0.935361\n",
      "pares          0.932017\n",
      "dares          0.931812\n",
      "COMBINED SCORE: (sqrt(word_frequency) * info_gain)\n",
      "       Combined Score  Information Gain  Word Frequency\n",
      "other        0.471749          0.528214        0.797631\n",
      "about        0.452289          0.452289        1.000000\n",
      "games        0.422009          0.845055        0.249386\n",
      "years        0.421771          0.803703        0.275399\n",
      "their        0.418910          0.524393        0.638157\n",
      "state        0.395993          0.651575        0.369358\n",
      "pages        0.370894          0.849213        0.190751\n",
      "first        0.370403          0.539541        0.471301\n",
      "there        0.369027          0.488115        0.571575\n",
      "terms        0.364863          0.766853        0.226378\n",
      "\n",
      "Guess 1 (or type \"exit\", \"restart\"): exit\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Allowed letters\n",
    "    a = [set(az) for _ in range(5)]\n",
    "    # Necessary letters\n",
    "    b = set()\n",
    "    \n",
    "    quit = False\n",
    "    \n",
    "    print('WORDLE SOLVER')\n",
    "    print('With no contraints, there are...')\n",
    "    find_clues_solutions(a,b)\n",
    "\n",
    "    for i in range(6):\n",
    "        word = input(f'Guess {i+1} (or type \"exit\", \"restart\"): ')\n",
    "        if word == 'restart':\n",
    "            break\n",
    "        elif word == 'exit':\n",
    "            quit = True\n",
    "            break\n",
    "        result = input('Result? (0=grey, 1=yellow, 2=green:\\n')\n",
    "        result = [sh[int(s)] for s in result]\n",
    "        use_clues(word, result)\n",
    "#         print('Best solution word is:', find_solution(a, b))\n",
    "#         print('Best clue word is:', find_clue(a,b))\n",
    "        find_clues_solutions(a, b)\n",
    "        print('')\n",
    "        \n",
    "    if quit:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>position</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tares</th>\n",
       "      <td>27396.857394</td>\n",
       "      <td>10781.425154</td>\n",
       "      <td>0.953709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lares</th>\n",
       "      <td>27460.499011</td>\n",
       "      <td>10532.511384</td>\n",
       "      <td>0.943887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cares</th>\n",
       "      <td>26082.927054</td>\n",
       "      <td>10887.691356</td>\n",
       "      <td>0.935361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pares</th>\n",
       "      <td>26061.732612</td>\n",
       "      <td>10820.055129</td>\n",
       "      <td>0.932017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dares</th>\n",
       "      <td>26511.353264</td>\n",
       "      <td>10636.135606</td>\n",
       "      <td>0.931812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infix</th>\n",
       "      <td>8299.023116</td>\n",
       "      <td>1674.794133</td>\n",
       "      <td>0.218980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kudzu</th>\n",
       "      <td>7023.637653</td>\n",
       "      <td>2179.129019</td>\n",
       "      <td>0.218799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oxbow</th>\n",
       "      <td>7550.825748</td>\n",
       "      <td>1440.363057</td>\n",
       "      <td>0.195572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>immix</th>\n",
       "      <td>6154.652583</td>\n",
       "      <td>1853.214489</td>\n",
       "      <td>0.189254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xylyl</th>\n",
       "      <td>5849.011578</td>\n",
       "      <td>1750.536914</td>\n",
       "      <td>0.179388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12947 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            overall      position       avg\n",
       "tares  27396.857394  10781.425154  0.953709\n",
       "lares  27460.499011  10532.511384  0.943887\n",
       "cares  26082.927054  10887.691356  0.935361\n",
       "pares  26061.732612  10820.055129  0.932017\n",
       "dares  26511.353264  10636.135606  0.931812\n",
       "...             ...           ...       ...\n",
       "infix   8299.023116   1674.794133  0.218980\n",
       "kudzu   7023.637653   2179.129019  0.218799\n",
       "oxbow   7550.825748   1440.363057  0.195572\n",
       "immix   6154.652583   1853.214489  0.189254\n",
       "xylyl   5849.011578   1750.536914  0.179388\n",
       "\n",
       "[12947 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Information Gain  Word Frequency   word  info_idx  freq_idx  combined_flat\n",
      "0      27396.857394    10781.425154  tares     12917     12935        12926.0\n",
      "1      27460.499011    10532.511384  lares     12934     12913        12923.5\n",
      "2      26511.353264    10636.135606  dares     12882     12924        12903.0\n",
      "3      27460.499011    10226.761744  rales     12931     12875        12903.0\n",
      "4      26586.236196    10424.431569  tales     12899     12899        12899.0\n"
     ]
    }
   ],
   "source": [
    "best_of_both = best_words.copy()[['overall', 'position']]\n",
    "best_of_both.columns = ['Information Gain', 'Word Frequency']\n",
    "best_of_both['word'] = best_of_both.index\n",
    "best_of_both = best_of_both.sort_values(['Information Gain']).reset_index().drop(['index'],axis=1)\n",
    "best_of_both['info_idx'] = best_of_both.index\n",
    "best_of_both = best_of_both.sort_values(['Word Frequency']).reset_index().drop(['index'],axis=1)\n",
    "best_of_both['freq_idx'] = best_of_both.index\n",
    "\n",
    "info_weight = 0.5\n",
    "freq_weight = 0.5\n",
    "best_of_both['combined_flat'] = best_of_both['info_idx']*info_weight + best_of_both['freq_idx']*freq_weight\n",
    "best_of_both = best_of_both.sort_values(['combined_flat'], ascending=False).reset_index().drop(['index'],axis=1)\n",
    "print(best_of_both.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
